import json
import os
import re
import logging
from typing import List, Dict
from telegram import (
    Update,
    InlineQueryResultArticle,
    InputTextMessageContent,
    InlineKeyboardButton,
    InlineKeyboardMarkup
)
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    InlineQueryHandler,
    filters,
    CallbackContext,
)

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("bot.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)

# === –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===
try:
    with open("config.json", "r") as config_file:
        config = json.load(config_file)
        TOKEN = config.get("TOKEN", "")
        if not TOKEN:
            raise ValueError("–¢–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ config.json")
except Exception as e:
    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
    raise

# === –ö–∞—Ä—Ç–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏–º–≤–æ–ª–æ–≤ ===
ACCENT_MAP = {
    "ƒÅ": "a",
    "ƒ´": "i",
    "≈´": "u",
    "·∏ç": "d",
    "·∏∑": "l",
    "·πÉ": "m",
    "·πÅ": "m",
    "·πÖ": "n",
    "·πá": "n",
    "·π≠": "t",
    "√±": "n",
    "√±√±": "n",
    "ss": "s",
    "aa": "a",
    "ii": "i",
    "uu": "u",
    "dd": "d",
    "kk": "k",
    "·∏ç·∏ç": "d",
    "·∏∑·∏∑": "l",
    "·πá·πá": "n",
    "·π≠·π≠": "t",
    "cc": "c",
    "pp": "p",
    "cch": "c",
    "ch": "c",
    "kh": "k",
    "ph": "p",
    "th": "t",
    "·π≠h": "t"
}

# === –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è ===
def load_words() -> List[str]:
    try:
        path = os.path.join("assets", "sutta_words.txt")
        with open(path, "r", encoding="utf-8") as f:
            words = [line.strip() for line in f if line.strip()]
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(words)} —Å–ª–æ–≤ –¥–ª—è –∞–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç–∞")
            return words
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ª–æ–≤–∞—Ä—è: {e}")
        return []
 
WORDS = load_words()

# === –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ ===
def normalize(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞ —Å —É—á–µ—Ç–æ–º ACCENT_MAP"""
    return "".join(ACCENT_MAP.get(c, c) for c in text.lower())

# === –£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç ===
def autocomplete(prefix: str, min_length: int = 2, max_results: int = 28) -> List[str]:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç —Å –ª–æ–≥–∏–∫–æ–π –∫–∞–∫ –≤ JS-–∫–æ–¥–µ:
    1. –°–Ω–∞—á–∞–ª–∞ —Å–ª–æ–≤–∞, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å –ø—Ä–µ—Ñ–∏–∫—Å–∞
    2. –ó–∞—Ç–µ–º —Å–ª–æ–≤–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å
    3. –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
    """
    try:
        if not prefix or len(prefix) < min_length:
            return []

        normalized_prefix = normalize(prefix)
        
        # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º –¥–ª—è regex –∏ –¥–æ–±–∞–≤–ª—è–µ–º {1,2} –¥–ª—è –∫–∞–∂–¥–æ–π –±—É–∫–≤—ã (–∫–∞–∫ –≤ JS-–∫–æ–¥–µ)
        re_prefix = re.escape(normalized_prefix)
        modified_re = re.sub(r"([a-zA-Z])", r"\1{1,2}", re_prefix)
        
        # –†–µ–≥—É–ª—è—Ä–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞
        match_begin = re.compile(f"^{modified_re}", re.IGNORECASE)
        match_anywhere = re.compile(f"{modified_re}", re.IGNORECASE)
        
        # –°–Ω–∞—á–∞–ª–∞ —Å–ª–æ–≤–∞, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å –ø—Ä–µ—Ñ–∏–∫—Å–∞
        begin_matches = [
            word for word in WORDS
            if match_begin.search(normalize(word))
        ]
        
        # –ó–∞—Ç–µ–º —Å–ª–æ–≤–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ –ø—Ä–µ—Ñ–∏–∫—Å (–Ω–æ –Ω–µ –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å –Ω–µ–≥–æ)
        other_matches = [
            word for word in WORDS
            if match_anywhere.search(normalize(word)) and word not in begin_matches
        ]
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results = (begin_matches + other_matches)[:max_results]
        logger.debug(f"–ê–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç –¥–ª—è '{prefix}': –Ω–∞–π–¥–µ–Ω–æ {len(results)} –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤")
        return results
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç–∞: {e}")
        return []

# === –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã —Å –∫–Ω–æ–ø–∫–∞–º–∏ ===
def create_keyboard(query: str) -> InlineKeyboardMarkup:
    search_url = f"https://dhamma.gift/ru/?p=-kn&q={query.replace(' ', '+')}"
    dict_url = f"https://dpdict.net/ru/search_html?q={query.replace(' ', '+')}"
    
    return InlineKeyboardMarkup([
        [
            InlineKeyboardButton(text="üîé Dhamma.gift", url=search_url),
            InlineKeyboardButton(text="üìö –°–ª–æ–≤–∞—Ä—å", url=dict_url)
        ]
    ])

# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ ===
async def start(update: Update, context: CallbackContext):
    user = update.effective_user
    logger.info(f"–ö–æ–º–∞–Ω–¥–∞ /start –æ—Ç {user.id} ({user.full_name})")
    await update.message.reply_text(
        "–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n"
        "‚Ä¢ –ü—Ä—è–º—ã–µ –∑–∞–ø—Ä–æ—Å—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'sn12.2' –∏–ª–∏ 'dukkha')\n"
        "‚Ä¢ –î–ª—è –ø–æ–¥—Å–∫–∞–∑–æ–∫ –≤ –ª—é–±–æ–º —á–∞—Ç–µ: @dhammagift_bot —Å–ª–æ–≤–æ"
    )

# === –ò–Ω–ª–∞–π–Ω-—Ä–µ–∂–∏–º ===
async def inline_query(update: Update, context: CallbackContext):
    query = update.inline_query.query.strip()
    if not query or len(query) < 2:
        return

    logger.info(f"–ò–Ω–ª–∞–π–Ω-–∑–∞–ø—Ä–æ—Å: '{query}' –æ—Ç {update.inline_query.from_user.id}")
    suggestions = autocomplete(query, max_results=28)

    results = []
    for word in suggestions:
        keyboard = create_keyboard(word)
        
        results.append(
            InlineQueryResultArticle(
                id=word,
                title=word,
                input_message_content=InputTextMessageContent(word),
                description=f"–ù–∞–∂–º–∏—Ç–µ, —á—Ç–æ–±—ã –æ—Ç–ø—Ä–∞–≤–∏—Ç—å '{word}'",
                reply_markup=keyboard
            )
        )

    await update.inline_query.answer(results, cache_time=10)

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π ===
async def handle_message(update: Update, context: CallbackContext):
    text = update.message.text.strip()
    user = update.effective_user
    logger.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {user.id}: {text}")

    # –ê–≤—Ç–æ–∫–æ–º–ø–ª–∏—Ç –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤
    if len(text) < 5 and text.isalpha():
        suggestions = autocomplete(text)
        if suggestions:
            reply = "–í–æ–∑–º–æ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:\n" + "\n".join(f"- {w}" for w in suggestions)
            await update.message.reply_text(reply)
            return

    # –í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Ç–µ–ø–µ—Ä—å —Å –∫–Ω–æ–ø–∫–∞–º–∏
    keyboard = create_keyboard(text)
    await update.message.reply_text(
        text,
        reply_markup=keyboard
    )

# === –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ===
def main():
    logger.info("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    try:
        app = Application.builder().token(TOKEN).build()

        # –ö–æ–º–∞–Ω–¥—ã
        app.add_handler(CommandHandler("start", start))

        # –ò–Ω–ª–∞–π–Ω-—Ä–µ–∂–∏–º
        app.add_handler(InlineQueryHandler(inline_query))

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ã—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

        logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
        app.run_polling()
    except Exception as e:
        logger.critical(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {e}")

if __name__ == "__main__":
    main()